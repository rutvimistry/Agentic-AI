{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get repsonse from an LLM\n",
    "\n",
    "\n",
    "To get started, [get an API key](https://g.co/ai/idxGetGeminiKey) and replace the word `API KEY` below with your API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, I'm ready for the next user input.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key from the environment variable\n",
    "api_key = os.getenv(\"SECRET_KEY\")\n",
    "\n",
    "# Ensure the API key is not None\n",
    "if not api_key:\n",
    "    raise ValueError(\"API key not found. Please set SECRET_KEY in the .env file.\")\n",
    "\n",
    "# Configure the Generative AI library\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Define the prompt, query, and observation\n",
    "prompt = \"You are a helpful assistant.\"\n",
    "query = \"What is the weather today?\"\n",
    "observation = \"The user is asking about the current weather.\"\n",
    "\n",
    "# Combine the system prompt and user query\n",
    "full_prompt = f\"{prompt}\\n\\nUser: {query}\\nAssistant: {observation}\\n\\nUser:\"\n",
    "\n",
    "# Create a model and generate content\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(full_prompt)\n",
    "\n",
    "# Print the response\n",
    "if response and response.parts:\n",
    "    print(response.parts[0].text)\n",
    "else:\n",
    "    print(\"No response received.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build your own Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call 1:\n",
      "Observation: New York City, NY\n",
      "Call 2:\n",
      "Observation: New York City, NY\n",
      "Call 3:\n",
      "Observation: New York City, NY\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define your prompt and query\n",
    "prompt = \"\"\" \n",
    "You cycle through Thought, Action, PAUSE, Observation. At the end of the loop you output a final Answer. Your final answer should be highly specific to the observations you have from running\n",
    "the actions.\n",
    "1. Thought: Describe your thoughts about the question you have been asked.\n",
    "2. Action: run one of the actions available to you - then return PAUSE.\n",
    "3. PAUSE\n",
    "4. Observation: will be the result of running those actions.\n",
    "\n",
    "Available actions:\n",
    "- getCurrentWeather: \n",
    "    E.g. getCurrentWeather: Salt Lake City\n",
    "    Returns the current weather of the location specified.\n",
    "- getLocation:\n",
    "    E.g. getLocation: null\n",
    "    Returns user's location details. No arguments needed.\n",
    "\n",
    "Example session:\n",
    "Question: Please give me some ideas for activities to do this afternoon.\n",
    "Thought: I should look up the user's location so I can give location-specific activity ideas.\n",
    "Action: getLocation: null\n",
    "PAUSE\n",
    "\n",
    "You will be called again with something like this:\n",
    "Observation: \"New York City, NY\"\n",
    "\n",
    "Then you loop again:\n",
    "Thought: To get even more specific activity ideas, I should get the current weather at the user's location.\n",
    "Action: getCurrentWeather: New York City\n",
    "PAUSE\n",
    "\n",
    "You'll then output:\n",
    "Answer: <Suggested activities based on sunny weather that are highly specific to New York City and surrounding areas.>\n",
    "\"\"\"\n",
    "\n",
    "query = \"What is the current weather at my location?\"\n",
    "\n",
    "# Dummy functions to simulate API calls\n",
    "def getLocation(place=None):\n",
    "    return {\"city\": \"New York City\", \"state\": \"NY\", \"country\": \"USA\"}\n",
    "\n",
    "def getCurrentWeather(place=None):\n",
    "    return {\"temperature\": \"2\", \"unit\": \"F\", \"forecast\": \"snowy\"}\n",
    "\n",
    "# Map available functions\n",
    "available_functions = {\n",
    "    \"getLocation\": getLocation,\n",
    "    \"getCurrentWeather\": getCurrentWeather\n",
    "}\n",
    "\n",
    "# Simulate an LLM response generator (Replace this with your LLM integration)\n",
    "def call_llm(current_prompt):\n",
    "    # Simulated LLM response to match the defined actions\n",
    "    if \"getLocation\" in current_prompt:\n",
    "        return \"Observation: New York City, NY\"\n",
    "    elif \"getCurrentWeather\" in current_prompt:\n",
    "        return \"Observation: { location: 'New York City, NY', forecast: ['snowy'] }\"\n",
    "    else:\n",
    "        return \"No valid action found.\"\n",
    "\n",
    "# Regex for extracting actions\n",
    "action_regex = r\"^Action: (\\w+): (.*)$\"\n",
    "max_calls = 3\n",
    "\n",
    "# Initial prompt to start the loop\n",
    "current_prompt = f\"{prompt}\\n\\nQuestion: {query}\\nThought:\"\n",
    "\n",
    "for i in range(max_calls):\n",
    "    print(f\"Call {i + 1}:\")\n",
    "\n",
    "    # Simulate LLM response\n",
    "    response = call_llm(current_prompt)\n",
    "\n",
    "    # Check if response contains an observation\n",
    "    if response.startswith(\"Observation:\"):\n",
    "        observation = response.split(\"Observation:\")[1].strip()\n",
    "        print(\"Observation:\", observation)\n",
    "\n",
    "        # Update the prompt with the observation\n",
    "        current_prompt += f\"\\nObservation: {observation}\\nThought:\"\n",
    "    else:\n",
    "        # Try to find and execute an action\n",
    "        response_lines = response.strip().split(\"\\n\")\n",
    "        found_action_str = next((line for line in response_lines if re.match(action_regex, line)), None)\n",
    "\n",
    "        if found_action_str:\n",
    "            actions = re.match(action_regex, found_action_str)\n",
    "            if actions:\n",
    "                action, action_arg = actions.groups()\n",
    "                if action in available_functions:\n",
    "                    observation = available_functions[action](action_arg)\n",
    "                    print(\"Observation:\", observation)\n",
    "\n",
    "                    # Update the prompt with the action and observation\n",
    "                    current_prompt += f\"\\nAction: {action}: {action_arg}\\nObservation: {observation}\\nThought:\"\n",
    "                else:\n",
    "                    print(f\"Action '{action}' is not available.\")\n",
    "            else:\n",
    "                print(\"No valid action found.\")\n",
    "        else:\n",
    "            print(\"No valid action found.\")\n",
    "\n",
    "# Final answer generation\n",
    "#print(\"Final Answer:\", \"Based on the observations, the weather is snowy in New York City.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "out",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
